{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed77101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:20.917239Z",
     "start_time": "2022-01-13T22:28:17.931500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b019dc",
   "metadata": {},
   "source": [
    "## Modify Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88de2eef",
   "metadata": {},
   "source": [
    "### Create Merged .csv File with Data from All Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2df0a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:21.127626Z",
     "start_time": "2022-01-13T22:28:20.918213Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# setup global variables - data file directory and name\n",
    "DATA_FILES_DIR = 'data'\n",
    "DATA_FILE_NAME = 'data.csv.gz'\n",
    "\n",
    "all_data_files = os.listdir(DATA_FILES_DIR)\n",
    "\n",
    "def create_data_file():\n",
    "    # read each data original data file and concatanate it to single df\n",
    "    os.chdir(DATA_FILES_DIR)\n",
    "    df = pd.concat(map(pd.read_csv, all_data_files), ignore_index=True)\n",
    "    os.chdir('..')   # return to previous dir - main dir\n",
    "    \n",
    "    # remove some patterns from city column    \n",
    "    df['city'] = df['city'].str.replace(',Croatia', '')\n",
    "    df['city'] = df['city'].str.replace(r'+', ' ')\n",
    "    \n",
    "    # sort data by datetime and city and save it to .csv file\n",
    "    df = df.sort_values(by=['date_time', 'city'])\n",
    "    df.to_csv(DATA_FILE_NAME, index=False, compression='gzip')\n",
    "    print('Data processed successfully')\n",
    "\n",
    "# create data file if does not exist\n",
    "if not os.path.exists(DATA_FILE_NAME):\n",
    "    print('Creating data file')\n",
    "    create_data_file()\n",
    "else:\n",
    "    print('Data has already been processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af970948",
   "metadata": {},
   "source": [
    "## Import Data & Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35dcab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:26.838052Z",
     "start_time": "2022-01-13T22:28:21.129646Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data \n",
    "df_data = pd.read_csv(DATA_FILE_NAME, compression='gzip')\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b1841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:26.868957Z",
     "start_time": "2022-01-13T22:28:26.841013Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a93adcf",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3802bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:26.877911Z",
     "start_time": "2022-01-13T22:28:26.870926Z"
    }
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "CORRELATION_DIR = 'correlation_plots'\n",
    "\n",
    "# recreate directory if does not exist\n",
    "if not os.path.exists(CORRELATION_DIR):\n",
    "    print(f'Creating folder {CORRELATION_DIR}')\n",
    "    os.mkdir(CORRELATION_DIR)\n",
    "\n",
    "# to always have the newest plot versions, delete file before creating new one\n",
    "def remove_file_if_exists(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ec965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:26.889877Z",
     "start_time": "2022-01-13T22:28:26.880901Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to calculate correlation matrix values\n",
    "def create_correlation_matrix(data, towns, field):\n",
    "    towns_cnt = len(towns)\n",
    "    # init zero matrix with m=n=count of cities \n",
    "    # set values to -13, just to be sure it is an imposible correlation value\n",
    "    ret_matrix = np.zeros((towns_cnt, towns_cnt)) - 13 \n",
    "\n",
    "    # iterate through every city combination and calculate the correlation\n",
    "    # normalize the date for each town\n",
    "    for i, town1 in enumerate(towns):\n",
    "        town1_values = np.array(data.loc[data['city'] == town1][field])\n",
    "        town1_values = (town1_values - np.mean(town1_values)) / (np.std(town1_values) * len(town1_values))\n",
    "        # correlation 1 on diagonal\n",
    "        ret_matrix[i,i] = 1.0\n",
    "        \n",
    "        # having in mind that ret_matrix[i,j] == ret_matrix[j,i]\n",
    "        for j, town2 in enumerate(towns[i+1:], i+1):\n",
    "            town2_values = np.array(data.loc[data['city'] == town2][field])\n",
    "            town2_values = (town2_values - np.mean(town2_values)) / (np.std(town2_values))\n",
    "            ret_matrix[i,j] = np.correlate(town1_values, town2_values)[0]\n",
    "            ret_matrix[j,i] = ret_matrix[i,j]\n",
    "    \n",
    "    return ret_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17789cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:27.031495Z",
     "start_time": "2022-01-13T22:28:26.891872Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_towns = sorted(list(df_data['city'].unique()))\n",
    "\n",
    "CORRELATION_COLUMN = 'tempC'  # choose which column will be used for analysis\n",
    "CORRELATION_DATA_FILENAME = f'{CORRELATION_COLUMN}_correlation_data.npy'\n",
    "\n",
    "# check if we already have correlation matrix saved\n",
    "if os.path.exists(CORRELATION_DATA_FILENAME):\n",
    "    print('Correlation file exists!')\n",
    "    corr_matrix = np.load(CORRELATION_DATA_FILENAME)\n",
    "else:\n",
    "    print('Correlation file does not exist.. Creating one...')\n",
    "    corr_matrix = create_correlation_matrix(data=df_data, towns=unique_towns, field=CORRELATION_COLUMN)\n",
    "    np.save(CORRELATION_DATA_FILENAME, corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1caa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:48.125881Z",
     "start_time": "2022-01-13T22:28:27.035488Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot correlation matrix\n",
    "CORRELATION_MATRIX_FILENAME = f'{CORRELATION_DIR}/{CORRELATION_COLUMN}_correlation_matrix.png'\n",
    "remove_file_if_exists(CORRELATION_MATRIX_FILENAME)\n",
    "fig = px.imshow(corr_matrix, x=unique_towns, y=unique_towns,\n",
    "               width=1300, height=1300)\n",
    "fig.update_layout(title_text='Correlation Matrix', title_x=0.5)\n",
    "fig.write_image(CORRELATION_MATRIX_FILENAME)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b24e1da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:48.133866Z",
     "start_time": "2022-01-13T22:28:48.127848Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to plot correlation bar chart\n",
    "def plot_town_bar_chart(cor, towns, field):\n",
    "    asix_range = np.arange(0, len(towns))\n",
    "    for i, town in enumerate(towns):\n",
    "        CORRELATION_IMAGE_FILENAME = f'{CORRELATION_DIR}/{field}_{town}_correlation_chart.png'\n",
    "        remove_file_if_exists(CORRELATION_IMAGE_FILENAME)\n",
    "        \n",
    "        curr_towns = towns.copy()\n",
    "        curr_towns.remove(town)\n",
    "        \n",
    "        curr_values = cor[i]\n",
    "        curr_values = np.delete(curr_values, i)\n",
    "        \n",
    "        curr_df = pd.DataFrame({'CITY': curr_towns, 'VALUES': curr_values})\n",
    "        fig = px.bar(curr_df, x='CITY', y='VALUES',\n",
    "                    hover_name='CITY', width=1000, height=500)\n",
    "        fig.update_layout(title_text=f'Correlation - {town}', title_x=0.5)\n",
    "        fig.update_xaxes(tickangle=90, tickmode='linear', title='')\n",
    "        fig.update_yaxes(title='%', range=[0.5,1.01])\n",
    "        fig.write_image(CORRELATION_IMAGE_FILENAME)\n",
    "        \n",
    "        if town == 'Rijeka':\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d4e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:59.262248Z",
     "start_time": "2022-01-13T22:28:48.135828Z"
    }
   },
   "outputs": [],
   "source": [
    "# call function for creating bar charts for each town\n",
    "plot_town_bar_chart(corr_matrix, unique_towns, CORRELATION_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e73195",
   "metadata": {},
   "source": [
    "## Correlation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220b852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:45:51.220064Z",
     "start_time": "2022-01-13T22:45:51.213083Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_graph(corr_matrix, unique_towns, unique_towns_index_sorted):\n",
    "    ret_graph = {}\n",
    "    for i in unique_towns_index_sort:\n",
    "        town1 = unique_towns[i]\n",
    "        ret_graph[town1] = []\n",
    "        # having in mind that ret_matrix[i,j] == ret_matrix[j,i]\n",
    "        for j in unique_towns_index_sort[i+1:]:\n",
    "            town2 = unique_towns[j]\n",
    "            if corr_matrix[i][j] < 0.95:\n",
    "                ret_graph[town1].append(town2)\n",
    "    \n",
    "    return ret_graph  \n",
    "\n",
    "# plot map with values from SVD_V (towns to concept)\n",
    "def plot_svd_map(unique_towns, vector, k, data_geo):\n",
    "    CORR_MAP_FILENAME = f'{CORRELATION_DIR}/{CORRELATION_COLUMN}_correlation_map.png'\n",
    "    remove_file_if_exists(CORR_MAP_FILENAME)\n",
    "    \n",
    "    data_geo['VALUES'] = vector\n",
    "    px.set_mapbox_access_token(open(\".mapbox_token\").read())\n",
    "    \n",
    "    fig = px.scatter_mapbox(data_geo, lat=\"LAT\", lon=\"LNG\", \n",
    "                            color=\"VALUES\", hover_name=\"CITY\", \n",
    "                            color_continuous_scale=px.colors.cyclical.Phase)\n",
    "    fig.write_image(CORR_MAP_FILENAME)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd9496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:45:54.950196Z",
     "start_time": "2022-01-13T22:45:54.909301Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort indexes of unique_towns based on lng, lat\n",
    "GEO_POSITION_FILENAME = 'geo_position.csv'\n",
    "df_geo_position = pd.read_csv(GEO_POSITION_FILENAME)\n",
    "df_geo_position.sort_values(by=['LNG', 'LAT'], inplace=True)\n",
    "\n",
    "unique_towns_index_sort = list(df_geo_position.index)\n",
    "corr_graph = create_graph(corr_matrix, unique_towns, unique_towns_index_sort)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6347c9",
   "metadata": {},
   "source": [
    "# Export to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a25b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:59.444667Z",
     "start_time": "2022-01-13T22:28:59.379896Z"
    }
   },
   "outputs": [],
   "source": [
    "# save notebook before nbconvert\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1fadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:59.518472Z",
     "start_time": "2022-01-13T22:28:59.449657Z"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28835c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:29:06.540573Z",
     "start_time": "2022-01-13T22:28:59.520465Z"
    }
   },
   "outputs": [],
   "source": [
    "# export notebook results to HTML\n",
    "!jupyter nbconvert --to=HTML correlation.ipynb"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
