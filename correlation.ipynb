{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ed77101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:20.917239Z",
     "start_time": "2022-01-13T22:28:17.931500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b52b448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"plotly_mimetype+notebook+vscode+pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b019dc",
   "metadata": {},
   "source": [
    "## Modify Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88de2eef",
   "metadata": {},
   "source": [
    "### Create Merged .csv File with Data from All Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf2df0a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:21.127626Z",
     "start_time": "2022-01-13T22:28:20.918213Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has already been processed\n"
     ]
    }
   ],
   "source": [
    "# setup global variables - data file directory and name\n",
    "DATA_FILES_DIR = 'original_data_files'\n",
    "DATA_FILE_NAME = 'data/data.csv.gz'\n",
    "\n",
    "all_data_files = os.listdir(DATA_FILES_DIR)\n",
    "\n",
    "def create_data_file():\n",
    "    # read each data original data file and concatanate it to single df\n",
    "    os.chdir(DATA_FILES_DIR)\n",
    "    df = pd.concat(map(pd.read_csv, all_data_files), ignore_index=True)\n",
    "    os.chdir('..')   # return to previous dir - main dir\n",
    "    \n",
    "    # remove some patterns from city column    \n",
    "    df['city'] = df['city'].str.replace(',Croatia', '')\n",
    "    df['city'] = df['city'].str.replace(r'+', ' ', regex=False)\n",
    "    \n",
    "    # fix json\n",
    "    df['weatherIconUrl'] = df['weatherIconUrl'].str.replace(\"\\[{'value': '\", \"\")\n",
    "    df['weatherIconUrl'] = df['weatherIconUrl'].str.replace(\"'}]\", \"\")\n",
    "\n",
    "    df['weatherDesc'] = df['weatherDesc'].str.replace(\"\\[{'value': '\", \"\")\n",
    "    df['weatherDesc'] = df['weatherDesc'].str.replace(\"'}]\", \"\")\n",
    "\n",
    "    # sort data by datetime and city and save it to .csv file\n",
    "    df = df.sort_values(by=['date_time', 'city'])\n",
    "    df.to_csv(DATA_FILE_NAME, index=False, compression='gzip')\n",
    "    print('Data processed successfully')\n",
    "\n",
    "# create data file if does not exist\n",
    "if not os.path.exists(DATA_FILE_NAME):\n",
    "    print('Creating data file')\n",
    "    create_data_file()\n",
    "else:\n",
    "    print('Data has already been processed')\n",
    "\n",
    "# import data \n",
    "df_full_data = pd.read_csv(DATA_FILE_NAME, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a93adcf",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22252bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        print(f'Creating folder {folder_name}')\n",
    "        os.mkdir(folder_name)\n",
    "\n",
    "# to always have the newest plot versions, delete file before creating new one\n",
    "def remove_file_if_exists(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "create_folder('data/')\n",
    "create_folder('data/correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbb0e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only needed data\n",
    "def truncate_df(df, columns_to_keep, years=None, months=None, hours=None, additional_conditions=None):\n",
    "    # modify timestamp column\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'],format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # build prefix str\n",
    "    prefix_str = 'columns-' + '_'.join(columns_to_keep)\n",
    "    \n",
    "    if additional_conditions:\n",
    "        for additional_condition in additional_conditions:\n",
    "            column, sign, value = additional_condition\n",
    "            if sign == '<':\n",
    "                df = df.loc[df[column] < value]\n",
    "            elif sign == '>':\n",
    "                df = df.loc[df[column] > value]\n",
    "            elif sign == '=':\n",
    "                df = df.loc[df[column] == value]\n",
    "            elif sign == 'in':\n",
    "                df = df.loc[df[column].isin(value)]\n",
    "            prefix_str += f'-condition-{column}-{sign}-' + '_'.join(value)\n",
    "    \n",
    "    columns_to_keep = ['date_time'] + columns_to_keep + ['city']\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    if years:\n",
    "        df = df[df['date_time'].dt.year.isin(years)]\n",
    "        prefix_str += '-years-' + '_'.join(map(str, years))\n",
    "\n",
    "    if months:\n",
    "        df = df[df['date_time'].dt.month.isin(months)]\n",
    "        prefix_str += '-months-' + '_'.join(map(str, months))\n",
    "\n",
    "    if hours:\n",
    "        df = df[df['date_time'].dt.hour.isin(hours)]\n",
    "        prefix_str += '-hours-' + '_'.join(map(str, hours))\n",
    "    \n",
    "    prefix_str = prefix_str.replace(' ', '')\n",
    "    return df, prefix_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e61ec965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:26.889877Z",
     "start_time": "2022-01-13T22:28:26.880901Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to calculate correlation matrix values\n",
    "def create_correlation_matrix(data, towns, field):\n",
    "    if len(field) == 1:\n",
    "        field = field[0]\n",
    "    else:\n",
    "        pass\n",
    "        # TO DO - merge and somehow calculate on multiple fields\n",
    "    \n",
    "    towns_cnt = len(towns)\n",
    "    # init zero matrix with m=n=count of cities \n",
    "    # set values to -13, just to be sure it is an imposible correlation value\n",
    "    ret_matrix = np.zeros((towns_cnt, towns_cnt)) - 13 \n",
    "\n",
    "    # iterate through every city combination and calculate the correlation\n",
    "    # normalize the date for each town\n",
    "    for i, town1 in enumerate(towns):\n",
    "        town1_values = np.array(data.loc[data['city'] == town1][field])\n",
    "        town1_values = (town1_values - np.mean(town1_values)) / (np.std(town1_values) * len(town1_values))\n",
    "        # correlation 1 on diagonal\n",
    "        ret_matrix[i,i] = 1.0\n",
    "        \n",
    "        # having in mind that ret_matrix[i,j] == ret_matrix[j,i]\n",
    "        for j, town2 in enumerate(towns[i+1:], i+1):\n",
    "            town2_values = np.array(data.loc[data['city'] == town2][field])\n",
    "            town2_values = (town2_values - np.mean(town2_values)) / (np.std(town2_values))\n",
    "            ret_matrix[i,j] = np.correlate(town1_values, town2_values)[0]\n",
    "            ret_matrix[j,i] = ret_matrix[i,j]  \n",
    "\n",
    "    return ret_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30ac6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full_data['weatherDesc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17789cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:27.031495Z",
     "start_time": "2022-01-13T22:28:26.891872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "Creating folder correlation_plots/columns-tempC-condition-weatherDesc-in-Partlycloudy_Cloudy\n",
      "Correlation file does not exist.. Creating one...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/HDD/00-Development/016-Diplomski/correlation.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000010?line=35'>36</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000010?line=36'>37</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCorrelation file does not exist.. Creating one...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000010?line=37'>38</a>\u001b[0m     corr_matrix \u001b[39m=\u001b[39m create_correlation_matrix(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000010?line=38'>39</a>\u001b[0m         data\u001b[39m=\u001b[39;49mdf_data, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000010?line=39'>40</a>\u001b[0m         towns\u001b[39m=\u001b[39;49munique_towns, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000010?line=40'>41</a>\u001b[0m         field\u001b[39m=\u001b[39;49mCOLUMNS_TO_KEEP\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000010?line=41'>42</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000010?line=42'>43</a>\u001b[0m     np\u001b[39m.\u001b[39msave(CORRELATION_DATA_FILENAME, corr_matrix)\n",
      "\u001b[1;32m/home/HDD/00-Development/016-Diplomski/correlation.ipynb Cell 9'\u001b[0m in \u001b[0;36mcreate_correlation_matrix\u001b[0;34m(data, towns, field)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000008?line=21'>22</a>\u001b[0m \u001b[39m# having in mind that ret_matrix[i,j] == ret_matrix[j,i]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000008?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m j, town2 \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(towns[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:], i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000008?line=23'>24</a>\u001b[0m     town2_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data\u001b[39m.\u001b[39mloc[data[\u001b[39m'\u001b[39;49m\u001b[39mcity\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m town2][field])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000008?line=24'>25</a>\u001b[0m     town2_values \u001b[39m=\u001b[39m (town2_values \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(town2_values)) \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39mstd(town2_values))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/HDD/00-Development/016-Diplomski/correlation.ipynb#ch0000008?line=25'>26</a>\u001b[0m     ret_matrix[i,j] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcorrelate(town1_values, town2_values)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/common.py?line=65'>66</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/common.py?line=67'>68</a>\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/common.py?line=69'>70</a>\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m/home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/arraylike.py?line=37'>38</a>\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/arraylike.py?line=38'>39</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/arraylike.py?line=39'>40</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m/home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/series.py?line=5619'>5620</a>\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/series.py?line=5621'>5622</a>\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/series.py?line=5622'>5623</a>\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/series.py?line=5624'>5625</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:283\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py?line=279'>280</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py?line=281'>282</a>\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py?line=282'>283</a>\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py?line=284'>285</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py?line=285'>286</a>\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:73\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py?line=70'>71</a>\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[1;32m     <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py?line=71'>72</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py?line=72'>73</a>\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[1;32m     <a href='file:///home/HDD/00-Development/016-Diplomski/venv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py?line=73'>74</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "CORRELATION_DIR = 'correlation_plots'\n",
    "# select which columns to keep\n",
    "COLUMNS_TO_KEEP = ['tempC']\n",
    "# COLUMNS_TO_KEEP = ['humidity']\n",
    "\n",
    "# create directory if does not exist\n",
    "create_folder(CORRELATION_DIR)\n",
    "\n",
    "# list of all towns\n",
    "unique_towns = sorted(list(df_full_data['city'].unique()))\n",
    "\n",
    "# create dataframe and string needed to create out files\n",
    "df_data, PREFIX_STR = truncate_df(\n",
    "    df=df_full_data,\n",
    "    columns_to_keep=COLUMNS_TO_KEEP,\n",
    "    # months=[6,7,8,9]\n",
    "    # additional_conditions=[('weatherDesc', 'in', ['Clear', 'Sunny', ], )]\n",
    "    additional_conditions=[('weatherDesc', 'in', ['Partly cloudy', 'Cloudy', ], )]\n",
    ")\n",
    "\n",
    "# modify output folder\n",
    "CORRELATION_DIR = f'{CORRELATION_DIR}/{PREFIX_STR}'\n",
    "create_folder(CORRELATION_DIR)\n",
    "\n",
    "CORRELATION_DATA_FILENAME = f'data/correlation/{PREFIX_STR}_correlation_data.npy'\n",
    "\n",
    "# check if we already have correlation matrix saved\n",
    "if os.path.exists(CORRELATION_DATA_FILENAME):\n",
    "    print('Correlation file exists!')\n",
    "    corr_matrix = np.load(CORRELATION_DATA_FILENAME)\n",
    "else:\n",
    "    print('Correlation file does not exist.. Creating one...')\n",
    "    corr_matrix = create_correlation_matrix(\n",
    "        data=df_data, \n",
    "        towns=unique_towns, \n",
    "        field=COLUMNS_TO_KEEP\n",
    "    )\n",
    "    np.save(CORRELATION_DATA_FILENAME, corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1caa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:48.125881Z",
     "start_time": "2022-01-13T22:28:27.035488Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot correlation matrix\n",
    "CORRELATION_MATRIX_FILENAME = f'{CORRELATION_DIR}/{PREFIX_STR}_correlation_matrix.png'\n",
    "remove_file_if_exists(CORRELATION_MATRIX_FILENAME)\n",
    "fig = px.imshow(\n",
    "    corr_matrix, \n",
    "    x=unique_towns, \n",
    "    y=unique_towns,\n",
    "    width=1300,\n",
    "    height=1300\n",
    ")\n",
    "fig.update_layout(\n",
    "    title_text=f'Correlation Matrix Analysis', \n",
    "    title_x=0.5\n",
    ")\n",
    "fig.write_image(CORRELATION_MATRIX_FILENAME)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b24e1da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:48.133866Z",
     "start_time": "2022-01-13T22:28:48.127848Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to plot correlation bar chart\n",
    "def plot_town_bar_chart(cor, towns, field):\n",
    "    for i, town in enumerate(towns):\n",
    "        CORRELATION_IMAGE_FILENAME = f'{CORRELATION_DIR}/{field}_{town}_correlation_chart.png'\n",
    "        remove_file_if_exists(CORRELATION_IMAGE_FILENAME)\n",
    "        \n",
    "        curr_towns = towns.copy()\n",
    "        curr_towns.remove(town)\n",
    "        \n",
    "        curr_values = cor[i]\n",
    "        curr_values = np.delete(curr_values, i)\n",
    "        \n",
    "        curr_df = pd.DataFrame({'CITY': curr_towns, 'VALUES': curr_values})\n",
    "        \n",
    "        fig = px.bar(\n",
    "            curr_df, \n",
    "            x='CITY', \n",
    "            y='VALUES',\n",
    "            hover_name='CITY', \n",
    "            width=1000, \n",
    "            height=500\n",
    "        )\n",
    "        fig.update_layout(title_text=f'Correlation - {town}', title_x=0.5)\n",
    "        fig.update_xaxes(\n",
    "            tickangle=90, \n",
    "            tickmode='linear', \n",
    "            title=''\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            title='%', \n",
    "            range=[0.5,1.01]\n",
    "        )\n",
    "        fig.write_image(CORRELATION_IMAGE_FILENAME)\n",
    "        \n",
    "        if town == 'Rijeka':\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d4e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:59.262248Z",
     "start_time": "2022-01-13T22:28:48.135828Z"
    }
   },
   "outputs": [],
   "source": [
    "# call function for creating bar charts for each town\n",
    "plot_town_bar_chart(\n",
    "    cor=corr_matrix, \n",
    "    towns=unique_towns, \n",
    "    field=PREFIX_STR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e73195",
   "metadata": {},
   "source": [
    "## Correlation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot map with values from SVD_V (towns to concept)\n",
    "def plot_correlation_map(partitions, data_geo, corr_matrix, map_borders):\n",
    "    named_colorscales = px.colors.DEFAULT_PLOTLY_COLORS * 10\n",
    "    CORR_MAP_FILENAME = f'{CORRELATION_DIR}/{PREFIX_STR}_correlation_map_{len(partitions)}communities.png'\n",
    "    remove_file_if_exists(CORR_MAP_FILENAME)\n",
    "    \n",
    "    mapbox_access_token = (open(\".mapbox_token\").read())\n",
    "    fig = go.Figure()\n",
    "    fig.update_layout(\n",
    "        width=1800,\n",
    "        height=800,\n",
    "    )\n",
    "    \n",
    "    # create a list with all dfs to plot cities in scatter plot at the end\n",
    "    list_data_geo_nodes = []\n",
    "    \n",
    "    # itterate through partitions and draw them on the map\n",
    "    for i, partition in enumerate(partitions):\n",
    "        # cast set to list and extract wanted cities from df \n",
    "        partition = list(partition)\n",
    "    \n",
    "        # if there is a single element in the partition, print it\n",
    "        data_geo_nodes = data_geo.loc[data_geo.index.isin(partition)]\n",
    "        if len(partition) < 2:\n",
    "            ind = partition[0]\n",
    "            print(f'There is a single element partition: {unique_towns[ind]}')\n",
    "            fig.add_trace(\n",
    "                go.Scattermapbox(\n",
    "                    mode = \"markers\",\n",
    "                    lon=data_geo_nodes['LNG'],\n",
    "                    lat=data_geo_nodes['LAT'],\n",
    "                    name=data_geo_nodes['CITY'].values[0],\n",
    "                    legendgroup=f'Partition {i+1}',\n",
    "                    showlegend=True,\n",
    "                    marker=dict(color=named_colorscales[i], size=14)\n",
    "                )\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # append df to list\n",
    "        list_data_geo_nodes.append(data_geo_nodes)\n",
    "\n",
    "        # itterate through elements in partition and plot the pairs\n",
    "        for j in range(len(partition)-1):\n",
    "            # extract values\n",
    "            corr_value = corr_matrix[partition[j], partition[j+1]]\n",
    "            nodes_index = [partition[j], partition[j+1]]\n",
    "\n",
    "            # truncate df to just two cities\n",
    "            data_geo_pair = data_geo_nodes.loc[data_geo_nodes.index.isin(nodes_index)]\n",
    "            city_from, city_to = data_geo_nodes.at[partition[j], \"CITY\"], data_geo_nodes.at[partition[j+1], \"CITY\"]\n",
    "\n",
    "            # calculate scaled width and opacity\n",
    "            scaled_width = scale_range(\n",
    "                old_value=corr_value,\n",
    "                corr_matrix=corr_matrix,\n",
    "                new_min=0.5,\n",
    "                new_max=3.5,\n",
    "            )\n",
    "            scaled_opacity = scale_range(\n",
    "                old_value=corr_value,\n",
    "                corr_matrix=corr_matrix,\n",
    "                new_min=0.3,\n",
    "                new_max=1.0,\n",
    "            )\n",
    "            \n",
    "            # draw lines and group them by partitions using legendgroup \n",
    "            fig.add_trace(\n",
    "                go.Scattermapbox(\n",
    "                    mode = \"lines\",\n",
    "                    lon = data_geo_pair['LNG'],\n",
    "                    lat = data_geo_pair['LAT'],\n",
    "                    name=f'{city_from} - {city_to}: corr:{round(corr_value, 2)}',\n",
    "                    legendgroup=f'Partition {i+1}',\n",
    "                    showlegend=True,\n",
    "                    line=dict(color=named_colorscales[i], width=scaled_width),\n",
    "                    opacity=scaled_opacity\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # plot cities as scatters on the map with different color\n",
    "    all_data_geo_nodes = pd.concat(list_data_geo_nodes)\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            mode = \"markers\",\n",
    "            lon = all_data_geo_nodes['LNG'],\n",
    "            lat = all_data_geo_nodes['LAT'],\n",
    "            text=all_data_geo_nodes['CITY'],\n",
    "            showlegend=False,\n",
    "            marker=dict(color=named_colorscales[i+1], size=7)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # setup layout parameters\n",
    "    fig.update_layout(\n",
    "        width=1485,\n",
    "        height=700,\n",
    "        margin = {\n",
    "            'l':15,\n",
    "            'r':35,\n",
    "            't':35,\n",
    "            'b':15,\n",
    "        },\n",
    "        autosize=True,\n",
    "        mapbox = {\n",
    "            'accesstoken': mapbox_access_token, \n",
    "            'center': {\n",
    "                'lon': np.average(map_borders[0:2]), \n",
    "                'lat': np.average(map_borders[2:4])\n",
    "            },\n",
    "            'style': \"open-street-map\",\n",
    "            'zoom': 7.5\n",
    "        },\n",
    "        title_text=f'Correlation Between Cities ({len(partitions)} Partitions)', \n",
    "        title_x=0.5\n",
    "    )\n",
    "    \n",
    "    fig.write_image(CORR_MAP_FILENAME)\n",
    "    fig.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220b852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:45:51.220064Z",
     "start_time": "2022-01-13T22:45:51.213083Z"
    }
   },
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic as GD \n",
    "\n",
    "# function to scale up correlation values\n",
    "def scale_range(old_value, corr_matrix, new_min, new_max):\n",
    "    old_min = np.min(corr_matrix)\n",
    "    old_max = np.max(corr_matrix)\n",
    "\n",
    "    old_range = old_max - old_min\n",
    "    new_range = new_max - new_min\n",
    "    \n",
    "    if old_value == old_min:\n",
    "        return new_min\n",
    "\n",
    "    new_value = (((old_value - old_min) * new_range) / old_range) + new_min\n",
    "    return new_value\n",
    "\n",
    "# function to create graph from correlation matrix\n",
    "def create_graph(corr_matrix, towns_index, data_geo):\n",
    "    G = nx.Graph()\n",
    "    distance = np.zeros((len(towns_index), len(towns_index)))\n",
    "    for i in towns_index:\n",
    "        town1_data = (data_geo.iloc[i]['LAT'], data_geo.iloc[i]['LNG'])\n",
    "        for j in towns_index[i+1:]:\n",
    "            town2_data = (data_geo.iloc[j]['LAT'], data_geo.iloc[j]['LNG'])\n",
    "            distance[i][j] = GD(town1_data, town2_data).km\n",
    "            distance[j][i] = GD(town1_data, town2_data).km\n",
    "    for i in towns_index:\n",
    "        for j in towns_index[i+1:]:\n",
    "            G.add_edge(i, j, weight=corr_matrix[i,j])\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd9496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:45:54.950196Z",
     "start_time": "2022-01-13T22:45:54.909301Z"
    }
   },
   "outputs": [],
   "source": [
    "# import cities with its logitude and latitude\n",
    "GEO_POSITION_FILENAME = 'data/geo_position.csv'\n",
    "df_geo_position = pd.read_csv(GEO_POSITION_FILENAME, )\n",
    "df_geo_position.sort_values(by=['CITY'], inplace=True)\n",
    "df_geo_position.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# left right up down\n",
    "map_borders = (\n",
    "    np.min(df_geo_position['LNG']),\n",
    "    np.max(df_geo_position['LNG']),\n",
    "    np.max(df_geo_position['LAT']),\n",
    "    np.min(df_geo_position['LAT']),\n",
    ")\n",
    "\n",
    "# call function to create graph G\n",
    "G = create_graph(\n",
    "    corr_matrix=corr_matrix,\n",
    "    towns_index=list(df_geo_position.index),\n",
    "    data_geo=df_geo_position\n",
    ")\n",
    "\n",
    "# send G to create n partitions and plot them on data\n",
    "resoultion_value = 1\n",
    "min_no_of_communities = 4\n",
    "while True:\n",
    "    while True:\n",
    "        G_partitions = nx.algorithms.community.louvain_communities(\n",
    "            G=G, \n",
    "            weight='weight', \n",
    "            seed=100, \n",
    "            threshold=1e-07, \n",
    "            resolution=resoultion_value\n",
    "        )\n",
    "        curr_len = len(G_partitions)\n",
    "        if curr_len >= min_no_of_communities:\n",
    "            break\n",
    "        resoultion_value += 0.001\n",
    "\n",
    "    # break if there are 3 more communities than minimum set\n",
    "    if len(G_partitions) >= min_no_of_communities + 3 or min_no_of_communities == 8:\n",
    "        break\n",
    "\n",
    "    # order them by number of cities in partition (just to have it better drawn)\n",
    "    G_partitions.sort(key=len)\n",
    "    \n",
    "    print(f'Min comumunities: {min_no_of_communities} -- Resoluton value: {resoultion_value}')\n",
    "\n",
    "    # plot map\n",
    "    plot_correlation_map(\n",
    "        partitions=G_partitions, \n",
    "        data_geo=df_geo_position, \n",
    "        corr_matrix=corr_matrix, \n",
    "        map_borders=map_borders,\n",
    "    )\n",
    "    \n",
    "    # increase min no of communities\n",
    "    min_no_of_communities += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6347c9",
   "metadata": {},
   "source": [
    "# Export to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a25b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:59.444667Z",
     "start_time": "2022-01-13T22:28:59.379896Z"
    }
   },
   "outputs": [],
   "source": [
    "# save notebook before nbconvert\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1fadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:28:59.518472Z",
     "start_time": "2022-01-13T22:28:59.449657Z"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28835c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T22:29:06.540573Z",
     "start_time": "2022-01-13T22:28:59.520465Z"
    }
   },
   "outputs": [],
   "source": [
    "# export notebook results to HTML and PDF\n",
    "jupyter_out_filename = f'{PREFIX_STR}_correlation'\n",
    "!jupyter nbconvert --output-dir 'output' --output {jupyter_out_filename} --to=HTML correlation.ipynb\n",
    "!jupyter nbconvert --output-dir 'output' --output {jupyter_out_filename} --to=pdf correlation.ipynb\n",
    "\n",
    "jupyter_out_filename_no_code = f'{PREFIX_STR}_correlation_no_code'\n",
    "!jupyter nbconvert --output-dir 'output' --output {jupyter_out_filename_no_code} --no-input --to=HTML correlation.ipynb\n",
    "!jupyter nbconvert --output-dir 'output' --output {jupyter_out_filename_no_code} --no-input --to=pdf correlation.ipynb"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "769079bfd2f593738bdd7839f74288d023e8009b057a18c47c18c614eadd7a4d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
